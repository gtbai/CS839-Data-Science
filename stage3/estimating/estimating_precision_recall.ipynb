{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep 1: steps to install the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install py_entitymatching\n",
    "!pip install scipy\n",
    "!pip install numpy\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [NEED MODIFICATION: Modify this cell to point to the file location]\n",
    "# Prep 2: enter the file location on your harddisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_a = '<table_a_location_downloaded_from_cloudmatcher_loc>'\n",
    "table_b = '<table_a_location_downloaded_from_cloudmatcher_loc>'\n",
    "candidate_set = '<candidate_set_downloaded_from_cloudmatcher_loc>'\n",
    "prediction_set = '<prediction_set_downloaded_from_cloudmatcher_loc>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep 3: reading the files into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = pd.read_csv(table_a)\n",
    "dfb = pd.read_csv(table_b)\n",
    "dfc = pd.read_csv(candidate_set)\n",
    "dfp = pd.read_csv(prediction_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module: debug_blocker\n",
    "# Description: debug the blocking rule using the below script to ensure you are not dropping true matches\n",
    "# Note: You need to run Prep 1 and 2 in order to run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input format:\n",
    "# Format of table_a:\n",
    "# _id, attribute1, attribute2, ....., attributen\n",
    "\n",
    "# Format of table_b:\n",
    "# _id, attribute1, attribute2, ....., attributen\n",
    "\n",
    "# Format of candidate_set\n",
    "# A_id,B_id\n",
    "# where A_id is _id from table_a and B_id is the _id column value from table_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import py_entitymatching as em\n",
    "import pandas as pd\n",
    "\n",
    "def run_debug_blocker(table_a, table_b, table_a_key, table_b_key, candidate_set):\n",
    "    dfl = em.read_csv_metadata(table_a, key=table_a_key)\n",
    "    dfr = em.read_csv_metadata(table_b, key=table_b_key)\n",
    "\n",
    "    # reading the candidate set and adding key\n",
    "    dfcand = pd.read_csv(candidate_set)\n",
    "    dfcand.drop_duplicates(inplace=True)\n",
    "    dfcand.to_csv('cand_set_with_index.csv', index_label='id')\n",
    "\n",
    "    dfcset = em.read_csv_metadata('cand_set_with_index.csv', key='id', ltable=dfl, \n",
    "                                  rtable=dfr, fk_ltable='A_id', fk_rtable='B_id')\n",
    "\n",
    "    # running debug blocker to identify the records in A x B \\ C\n",
    "    debug_file = em.debug_blocker(dfcset, dfl, dfr)\n",
    "    \n",
    "    return debug_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_file = run_debug_blocker(table_a, table_b, '_id', '_id', candidate_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module: estimate_precision_recall\n",
    "# Description: the below code helps you get an estimation of P/R on the candidate set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from numpy import sqrt\n",
    "\n",
    "delta = .05\n",
    "Z = norm.ppf(1 - (delta / 2))\n",
    "\n",
    "def estimate_PR(labeled_pairs, reduced_cands, predicted_matches):\n",
    "    '''\n",
    "    labeled_pairs - a pandas dataframe with schema id1,id2,label\n",
    "                    Note label needs to be Boolean\n",
    "\n",
    "    reduced_cands - a pandas dataframe with schema id1,id2\n",
    "    predicted_matches - a pandas dataframe with schema id1,id2\n",
    "    \n",
    "    return:\n",
    "        ( (recall lower bound, recall upper bound), (precision lower bound, precision upper bound) )\n",
    "    '''\n",
    "\n",
    "    labeled_pairs.drop_duplicates(inplace=True)\n",
    "    labeled_pairs.columns = ['id1', 'id2', 'label']\n",
    "    reduced_cands.columns = ['id1', 'id2']\n",
    "    reduced_cand_set = set(zip(reduced_cands.id1, reduced_cands.id2))\n",
    "    predicted_matches = set(zip(predicted_matches.id1, predicted_matches.id2))\n",
    "    \n",
    "    # estimate the recall\n",
    "    # number of positives in the labeled sample\n",
    "    actual_pos = float(labeled_pairs.label.sum())\n",
    "    # the maximum number of postives in the candidate set\n",
    "    max_actual_pos = float(actual_pos + len(reduced_cand_set) - len(labeled_pairs))\n",
    "    \n",
    "    # true positives in the labeled sample\n",
    "    true_pos = float(labeled_pairs.apply(lambda x : (x['id1'], x['id2']) in predicted_matches and x['label'], axis=1).sum())\n",
    "    #estimated recall\n",
    "    recall = float(true_pos / actual_pos)\n",
    "\n",
    "    recall_error = Z * sqrt( ((recall * (1 - recall)) / (actual_pos)) * ((max_actual_pos - actual_pos) / (max_actual_pos - 1)) )\n",
    "\n",
    "\n",
    "    # estimate Precision\n",
    "    labeled_set  = set(zip(labeled_pairs.id1, labeled_pairs.id2))\n",
    "    predicted_pos = float(len(labeled_set & predicted_matches))\n",
    "    \n",
    "    predicted_pos_in_reduced_cand_set = float(len(reduced_cand_set & predicted_matches))\n",
    "    \n",
    "    alpha =  predicted_pos_in_reduced_cand_set / len(predicted_matches)\n",
    "    precision = alpha * (true_pos / predicted_pos)\n",
    "    \n",
    "    precision_error = alpha * Z * sqrt( ((precision * (1 - precision)) / predicted_pos) * (float((len(predicted_matches) - predicted_pos)) / (len(predicted_matches)  - 1)) )\n",
    "\n",
    "    return ((recall - recall_error, recall + recall_error),\n",
    "            (precision - precision_error, precision + precision_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [NEED MODIFICATION: Modify this cell to point to the file location]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((0.9825476990384129, 0.9981596964599794), (1.0, 1.0))\n"
     ]
    }
   ],
   "source": [
    "# read the labeled pairs file, i.e. the file with the labels\n",
    "labeled_pairs = pd.read_csv('labeled_pairs.csv')\n",
    "print(estimate_PR(labeled_pairs, dfc, dfp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternatively if you run into issues running this script on your laptop you can use\n",
    "# https://colab.research.google.com/notebooks/welcome.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
